/var/spool/slurmd.spool/job4320607/slurm_script: line 15: pips: command not found
Requirement already satisfied: nltk in /home/crsnell/.local/lib/python3.6/site-packages (3.6.7)
Requirement already satisfied: joblib in /home/crsnell/.local/lib/python3.6/site-packages (from nltk) (1.1.1)
Requirement already satisfied: tqdm in /home/crsnell/.local/lib/python3.6/site-packages (from nltk) (4.64.1)
Requirement already satisfied: regex>=2021.8.3 in /home/crsnell/.local/lib/python3.6/site-packages (from nltk) (2023.8.8)
Requirement already satisfied: click in /home/crsnell/.local/lib/python3.6/site-packages (from nltk) (8.0.4)
Requirement already satisfied: importlib-metadata in /home/crsnell/.local/lib/python3.6/site-packages (from click->nltk) (4.8.3)
Requirement already satisfied: importlib-resources in /home/crsnell/.local/lib/python3.6/site-packages (from tqdm->nltk) (5.4.0)
Requirement already satisfied: zipp>=0.5 in /home/crsnell/.local/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (3.6.0)
Requirement already satisfied: typing-extensions>=3.6.4 in /home/crsnell/.local/lib/python3.6/site-packages (from importlib-metadata->click->nltk) (4.1.1)
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/crsnell/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Traceback (most recent call last):
  File "scripts/preprocess_text.py", line 439, in <module>
    clean_csv_files(csv_dir, output_dir)
  File "scripts/preprocess_text.py", line 342, in clean_csv_files
    dfmax['comment_body'] = dfmax['comment_body'].apply(lambda x: clean_text_max(str(x)))
  File "/home/crsnell/.local/lib/python3.6/site-packages/pandas/core/series.py", line 4213, in apply
    mapped = lib.map_infer(values, f, convert=convert_dtype)
  File "pandas/_libs/lib.pyx", line 2403, in pandas._libs.lib.map_infer
  File "scripts/preprocess_text.py", line 342, in <lambda>
    dfmax['comment_body'] = dfmax['comment_body'].apply(lambda x: clean_text_max(str(x)))
  File "scripts/preprocess_text.py", line 397, in clean_text_max
    words = nltk.tokenize.word_tokenize(text.lower())
  File "/home/crsnell/.local/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 129, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
  File "/home/crsnell/.local/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 106, in sent_tokenize
    tokenizer = load(f"tokenizers/punkt/{language}.pickle")
  File "/home/crsnell/.local/lib/python3.6/site-packages/nltk/data.py", line 750, in load
    opened_resource = _open(resource_url)
  File "/home/crsnell/.local/lib/python3.6/site-packages/nltk/data.py", line 876, in _open
    return find(path_, path + [""]).open()
  File "/home/crsnell/.local/lib/python3.6/site-packages/nltk/data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/PY3/english.pickle[0m

  Searched in:
    - '/home/crsnell/nltk_data'
    - '/usr/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
    - ''
**********************************************************************

